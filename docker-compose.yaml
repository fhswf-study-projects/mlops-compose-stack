services:
  nginx-proxy:
    restart: always
    image: nginxproxy/nginx-proxy:${NGINX_PROXY_VERSION_TAG}
    container_name: nginx-proxy
    ports:
      - "80:80" # HTTP
      - "443:443" # HTTPS
    networks:
      - frontend
      - backend
    volumes:
      - ./configs/nginx/client_max_body_size.conf:/etc/nginx/conf.d/client_max_body_size.conf:ro
      - certs:/etc/nginx/certs
      - html:/usr/share/nginx/html
      - /var/run/docker.sock:/tmp/docker.sock:ro

  acme-companion:
    restart: always
    image: nginxproxy/acme-companion:${ACME_COMPANION_VERSION_TAG}
    container_name: nginx-proxy-acme
    networks:
      - backend
    environment:
      - DEFAULT_EMAIL=${LETSENCRYPT_DEFAULT_EMAIL}
    volumes:
      - certs:/etc/nginx/certs
      - html:/usr/share/nginx/html
      - acme:/etc/acme.sh
      - /var/run/docker.sock:/var/run/docker.sock:ro

  rabbitmq:
    restart: always
    image: rabbitmq:${RABBITMQ_VERSION_TAG}
    ports:
      - "${RABBITMQ_PORT}:5672"
    networks:
      - backend
    environment:
      - VIRTUAL_HOST=${RABBITMQ_VIRTUAL_HOST}
      - LETSENCRYPT_HOST=${RABBITMQ_VIRTUAL_HOST}
      - VIRTUAL_PORT=${RABBITMQ_VIRTUAL_PORT}
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASSWORD}
    volumes:
      - ./configs/rabbitmq/enabled_plugins:/etc/rabbitmq/enabled_plugins
      - ./configs/rabbitmq/30-management_agent.enable_metrics_collector.conf:/etc/rabbitmq/conf.d/management_agent.disable_metrics_collector.conf
      - ./configs/rabbitmq/40-consumer_timeout.conf:/etc/rabbitmq/conf.d/40-consumer_timeout.conf
      - rabbitmq_lib:/var/lib/rabbitmq/
      - rabbitmq_log:/var/log/rabbitmq/
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 30s
      retries: 3

  wait-for-rabbitmq:
    image: atkrad/wait4x
    depends_on:
      - rabbitmq
    command: rabbitmq "amqp://${RABBITMQ_DEFAULT_USER}:${RABBITMQ_DEFAULT_PASSWORD}@rabbitmq:${RABBITMQ_PORT}/" -t 90s -i 2000ms
    networks:
      - backend
  
  postgres:
    restart: always
    image: postgres:${POSTGRES_VERSION_TAG}
    ports:
      - "${PG_PORT}:5432"
    networks:
      - backend
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASSWORD}
      - POSTGRES_DB=${PG_DATABASE}
      - PG_MLFLOW_USER=${PG_MLFLOW_USER}
      - PG_MLFLOW_PASSWORD=${PG_MLFLOW_PASSWORD}
      - PG_MLFLOW_DB=${PG_MLFLOW_DATABASE}
      - PG_CELERY_USER=${PG_CELERY_USER}
      - PG_CELERY_PASSWORD=${PG_CELERY_PASSWORD}
      - PG_CELERY_DB=${PG_CELERY_DATABASE}
      - OTEL_USER=${OTEL_USER}
      - OTEL_PASSWORD=${OTEL_PASSWORD}
    volumes:
      - ./configs/postgres/init-user-db.sh:/docker-entrypoint-initdb.d/init-user-db.sh
      - postgres_data:/var/lib/postgresql/data/
    healthcheck:
      test: ["CMD", "pg_isready", "-p", "${PG_PORT}", "-U", "${PG_USER}"]
      interval: 5s
      timeout: 5s
      retries: 3

  wait-for-postgres:
    image: atkrad/wait4x
    depends_on:
      - postgres
    command: postgresql "postgresql://${PG_MLFLOW_USER}:${PG_MLFLOW_PASSWORD}@postgres:${PG_PORT}/${PG_MLFLOW_DATABASE}?sslmode=disable" -t 90s -i 2000ms
    networks:
      - backend

  s3:
    restart: always
    image: minio/minio:${MINIO_VERSION_TAG}
    networks:
      - frontend
      - backend
    environment:
      - VIRTUAL_HOST=${S3_VIRTUAL_HOST}
      - LETSENCRYPT_HOST=${S3_VIRTUAL_HOST}
      - VIRTUAL_PORT=${S3_VIRTUAL_PORT}
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_ACCESS_KEY}
      - MINIO_CONSOLE_ADDRESS=${MINIO_CONSOLE_ADDRESS}
    volumes:
      - minio_data:/data
    command: server /data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  createbuckets:
    image: minio/mc
    networks:
      - backend
    depends_on:
      - s3
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://s3:${MINIO_PORT} ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
      /usr/bin/mc mb myminio/${MLFLOW_BUCKET_NAME} --ignore-existing;
      /usr/bin/mc mb myminio/${DVC_BUCKET_NAME} --ignore-existing --with-versioning;
      /usr/bin/mc mb myminio/${CELERY_DATA_HOLDER_BUCKET_NAME} --ignore-existing --with-versioning;
      /usr/bin/mc admin user svcacct add --access-key "${MINIO_ACCESS_KEY}" --secret-key "${MINIO_SECRET_ACCESS_KEY}" myminio ${MINIO_ROOT_USER};
      exit 0;
      "
  
  mlflow-server:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    ports:
      - "${MLFLOW_PORT}:5000"
    networks:
      - frontend
      - backend
    environment:
      - VIRTUAL_HOST=${MLFLOW_VIRTUAL_HOST}
      - LETSENCRYPT_HOST=${MLFLOW_VIRTUAL_HOST}
      - VIRTUAL_PORT=${MLFLOW_VIRTUAL_PORT}
      - PORT=${MLFLOW_VIRTUAL_PORT}
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:${MINIO_PORT}
      - MLFLOW_S3_IGNORE_TLS=${MLFLOW_S3_IGNORE_TLS}
      - BACKEND_STORE_URI=postgresql://${PG_MLFLOW_USER}:${PG_MLFLOW_PASSWORD}@postgres:${PG_PORT}/${PG_MLFLOW_DATABASE}
      - ARTIFACTS_DESTINATION=s3://${MLFLOW_BUCKET_NAME}
    depends_on:
      wait-for-postgres:
        condition: service_completed_successfully

  otel-lgtm:
    image: grafana/otel-lgtm:${OTEL_VERSION_TAG}
    ports:
      - "${GRAFANA_PORT}:3000"
      - "4317:4317"
      - "4318:4318"
    networks:
      - frontend
      - backend
    environment:
      - VIRTUAL_HOST=${OTEL_VIRTUAL_HOST}
      - LETSENCRYPT_HOST=${OTEL_VIRTUAL_HOST}
      - VIRTUAL_PORT=${OTEL_VIRTUAL_PORT}
      - GF_SECURITY_ADMIN_USER=${GF_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_PASSWORD}
      - GF_PATHS_DATA=${GF_PATHS_DATA}
      - RABBITMQ_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_DEFAULT_PASSWORD}
      - RABBITMQ_PORT=${RABBITMQ_API_PORT}
      - OTEL_USER=${OTEL_USER}
      - OTEL_PASSWORD=${OTEL_PASSWORD}
      - ENABLE_LOGS_OTELCOL=${ENABLE_LOGS_OTELCOL}
    volumes:
      - ./collector/collector-config.yaml:/otel-lgtm/otelcol-config.yaml
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - loki_data:/data/loki
      - grafana_data:/data/grafana
      - prometheus_data:/data/prometheus
    depends_on:
      wait-for-postgres:
        condition: service_completed_successfully
      wait-for-rabbitmq:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${GRAFANA_PORT}/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # flower:
  #   # restart: always
  #   image: mher/flower
  #   networks:
  #     - frontend
  #     - backend
  #   environment:
  #     - VIRTUAL_HOST=celery.localhost
  #     - VIRTUAL_PORT=5555
  #     - CELERY_RESULT_BACKEND=postgresql://${PG_MLFLOW_USER}:${PG_MLFLOW_PASSWORD}@postgres:${PG_PORT}/${PG_MLFLOW_DATABASE}
  #     - CELERY_BROKER_URL=amqp://${RABBITMQ_DEFAULT_USER}:${RABBITMQ_DEFAULT_PASSWORD}@rabbitmq:${RABBITMQ_PORT}/
  #     - FLOWER_BROKER_API=http://${RABBITMQ_DEFAULT_USER}:${RABBITMQ_DEFAULT_PASSWORD}@rabbitmq:${RABBITMQ_API_PORT}/api/
  #   depends_on:
  #     wait-for-rabbitmq:
  #       condition: service_completed_successfully

  # Services
  pipeline-api:
    restart: always
    image: ghcr.io/fhswf-study-projects/mlops-pipeline-api:${DEPLOY_ENV}
    build:
      context: ./services/pipeline-api/
      dockerfile: Dockerfile
    develop:
      watch:
        - action: rebuild
          path: ./services/pipeline-api/poetry.lock
        - action: sync+restart
          path: ./services/pipeline-api
          target: /usr/src/app
    networks:
      - frontend
      - backend
    # env_file:
    #   - ./services/pipeline-api/.env
    depends_on:
      - postgres
      - rabbitmq
      - s3

  streamlit-ui:
    restart: always
    image: ghcr.io/fhswf-study-projects/mlops-streamlit-ui:${DEPLOY_ENV}
    build:
      context: ./services/streamlit-ui/
      dockerfile: Dockerfile
    develop:
      watch:
        - action: rebuild
          path: ./services/streamlit-ui/poetry.lock
        - action: sync+restart
          path: ./services/streamlit-ui
          target: /usr/src/app
    networks:
      - frontend
    # env_file:
    #   - ./services/streamlit-ui/.env
    depends_on:
      - otel-lgtm
      - pipeline-api

  data-processor:
    image: ghcr.io/fhswf-study-projects/mlops-data-processor:${DEPLOY_ENV}
    build:
      context: ./services/data-processor/
      dockerfile: Dockerfile
    develop:
      watch:
        - action: rebuild
          path: ./services/data-processor/poetry.lock
        - action: sync+restart
          path: ./services/data-processor
          target: /usr/src/app
    networks:
      - backend
    # env_file:
    #   - ./services/data-processor/.env
    depends_on:
      wait-for-postgres:
        condition: service_completed_successfully
      wait-for-rabbitmq:
        condition: service_completed_successfully

# # Use it for container debugging
# # Remove comments for starting with remote debugger
# # ports:
# #   - 5678:5678
# # entrypoint:
# #   ["sh","-c", "pip install debugpy -t /tmp && celery --quiet -A app.internals.celery.app worker --loglevel=FATAL"]

volumes:
  certs:
  html:
  acme:
  rabbitmq_lib:
  rabbitmq_log:
  postgres_data:
  minio_data:
  loki_data:
  grafana_data:
  prometheus_data:

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
